"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
/*
 * Copyright (C) 2023 by Fonoster Inc (https://fonoster.com)
 * http://github.com/fonoster/fonoster
 *
 * This file is part of Fonoster
 *
 * Licensed under the MIT License (the "License");
 * you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 *    https://opensource.org/licenses/MIT
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
const storage_pb_1 = require("./protos/storage_pb");
const core_1 = require("@fonoster/core");
const files_1 = require("../utils/files");
const helper_1 = require("../utils/helper");
const utils_1 = require("../utils/utils");
const logger_1 = __importDefault(require("@fonoster/logger"));
const fs_1 = __importDefault(require("fs"));
const objectid = require("bson-objectid");
async function default_1(call, callback) {
    const tmpName = objectid();
    const writeStream = fs_1.default.createWriteStream(`/tmp/${tmpName}`);
    let object;
    let bucket;
    let accessKeyId = (0, core_1.getAccessKeyId)(call);
    call.on("error", (err) => {
        logger_1.default.log("error", `@fonoster/storage upload [an error ocurred while uploading object ${object} to bucket '${bucket}']`);
        logger_1.default.log("error", err);
    });
    call.on("end", () => writeStream.end());
    call.on("data", (request) => {
        const chunk = request.getChunks();
        if (chunk.length === 0)
            return;
        writeStream.write(Buffer.alloc(chunk.length, chunk));
        if (!object && request.getFilename()) {
            object = request.getFilename();
            bucket = (0, utils_1.getBucketAsString)(request.getBucket());
            if (request.getAccessKeyId() &&
                request.getBucket() === storage_pb_1.UploadObjectRequest.Bucket.PUBLIC) {
                accessKeyId = request.getAccessKeyId();
            }
            logger_1.default.debug(`@fonoster/storage upload [started uploading object ${object} into "${bucket}" bucket]`);
        }
        logger_1.default.log("verbose", `@fonoster/storage upload [received chunk(${chunk.length}) for ${object}]`);
    });
    writeStream.on("finish", async () => {
        try {
            const fileSize = (0, files_1.getFilesizeInBytes)(`/tmp/${tmpName}`);
            fs_1.default.renameSync(`/tmp/${tmpName}`, `/tmp/${object}`);
            logger_1.default.verbose(`@fonoster/storage upload [moved ${tmpName} into ${object} (final name)]`);
            logger_1.default.verbose(`@fonoster/storage upload [uploading file to storage backend (s3)]`);
            const response = (0, files_1.isCompressFile)(object)
                ? await (0, helper_1.handleCompressUpload)(accessKeyId, object, bucket, fileSize)
                : await (0, helper_1.handleUncompressUpload)(accessKeyId, object, bucket, fileSize);
            logger_1.default.verbose(`@fonoster/storage upload [removing tmp file /tmp/${object}]`);
            fs_1.default.unlink(`/tmp/${object}`, () => callback(null, response));
        }
        catch (e) {
            logger_1.default.log("error", `@fonoster/storage upload [${e}]`);
            callback((0, utils_1.handleError)(e, bucket));
        }
    });
}
exports.default = default_1;
