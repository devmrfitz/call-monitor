"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.GoogleSpeechTracker = void 0;
const speech_1 = __importDefault(require("@google-cloud/speech"));
const stream_recognize_1 = __importDefault(require("./stream_recognize"));
const stream_speech_result_1 = __importDefault(require("./stream_speech_result"));
const defaultTrackerConfig = {
    config: {
        encoding: "LINEAR16",
        sampleRateHertz: 16000,
        languageCode: "en-US"
    },
    interimResults: false
};
class GoogleSpeechTracker {
    client;
    config;
    constructor(config) {
        const merge = require("deepmerge");
        this.config = merge(defaultTrackerConfig, { config } || {});
        this.client = new speech_1.default.SpeechClient(this.config.config);
    }
    streamTranscribe(stream) {
        let s = new stream_speech_result_1.default();
        new stream_recognize_1.default(this.config.config, stream, async (transcript, isFinal) => {
            s.emit({ transcript, isFinal });
        }, (result) => {
            // We are not yet doing diarization
        });
        return s;
    }
    transcribe(stream) {
        return new Promise((resolve, reject) => {
            const recognizeStream = this.client
                .streamingRecognize(this.config)
                .on("error", (e) => reject(e))
                .on("data", (data) => {
                if (data.results[0]?.alternatives[0]) {
                    const result = {
                        transcript: data.results[0].alternatives[0].transcript,
                        isFinal: true
                    };
                    resolve(result);
                }
                else {
                    resolve({ transcript: "", isFinal: true });
                }
            });
            stream.pipe(recognizeStream);
        });
    }
}
exports.GoogleSpeechTracker = GoogleSpeechTracker;
